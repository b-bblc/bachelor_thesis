{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021b3e83",
   "metadata": {},
   "source": [
    "# Dependency Parsing for English RST Example: EDUs and Whole Sentences\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "- Extract Elementary Discourse Units (EDUs) from an .rs3 file (RST format)\n",
    "- Parse each EDU using dependency parsing (spaCy)\n",
    "- Group EDUs into whole sentences and parse them as full sentences\n",
    "- Visualize the dependency trees for both EDUs and full sentences\n",
    "\n",
    "All comments and code are in English. Run each code cell step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c710cf",
   "metadata": {},
   "source": [
    "## 1. Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a33158",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da9d17d",
   "metadata": {},
   "source": [
    "## 2. Load the English spaCy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea4c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_en = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d25915",
   "metadata": {},
   "source": [
    "## 3. Extract EDUs from the .rs3 File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b0b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your .rs3 file (update as needed)\n",
    "rs3_path = \"#\"\n",
    "# Parse the XML structure and extract EDU segments\n",
    "root = ET.parse(rs3_path).getroot()\n",
    "edus = []\n",
    "for segment in root.findall(\".//segment\"):\n",
    "    edu_text = segment.text.strip() if segment.text else \"\"\n",
    "    if edu_text:\n",
    "        edus.append(edu_text)\n",
    "print(f\"Total EDUs extracted: {len(edus)}\")\n",
    "for i, e in enumerate(edus[:5]):\n",
    "    print(f\"EDU {i+1}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bdad61",
   "metadata": {},
   "source": [
    "## 4. Dependency Parsing for Each EDU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199decde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dependency tree for each EDU (in Jupyter only)\n",
    "for idx, edu in enumerate(edus):\n",
    "    print(f\"EDU {idx+1}: {edu}\")\n",
    "    doc = nlp_en(edu)\n",
    "    displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be798b",
   "metadata": {},
   "source": [
    "## 5. Group EDUs into Full Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9776bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_edus_to_sentences(edus):\n",
    "    sentences = []\n",
    "    buffer = []\n",
    "    for edu in edus:\n",
    "        buffer.append(edu)\n",
    "        # Check for sentence-final punctuation\n",
    "        if edu.strip().endswith(('.', '!', '?')):\n",
    "            sentences.append(\" \".join(buffer))\n",
    "            buffer = []\n",
    "    if buffer:\n",
    "        sentences.append(\" \".join(buffer))  # Add any remaining as a final sentence\n",
    "    return sentences\n",
    "\n",
    "sentences = group_edus_to_sentences(edus)\n",
    "print(f\"Total full sentences: {len(sentences)}\")\n",
    "for i, s in enumerate(sentences[:3]):\n",
    "    print(f\"Sentence {i+1}: {s}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f5a16",
   "metadata": {},
   "source": [
    "## 6. Dependency Parsing for Whole Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf29ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sent in enumerate(sentences):\n",
    "    print(f\"Full Sentence {idx+1}: {sent}\")\n",
    "    doc = nlp_en(sent)\n",
    "    displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a8ec77",
   "metadata": {},
   "source": [
    "## 7. (Optional) Save Visualizations as SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c95238",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"english_parse_svgs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "# Save for EDUs\n",
    "for idx, edu in enumerate(edus):\n",
    "    doc = nlp_en(edu)\n",
    "    svg = displacy.render(doc, style=\"dep\", jupyter=False)\n",
    "    (output_dir / f\"edu_{idx+1}_dep.svg\").write_text(svg, encoding=\"utf-8\")\n",
    "# Save for full sentences\n",
    "for idx, sent in enumerate(sentences):\n",
    "    doc = nlp_en(sent)\n",
    "    svg = displacy.render(doc, style=\"dep\", jupyter=False)\n",
    "    (output_dir / f\"sentence_{idx+1}_dep.svg\").write_text(svg, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb46be0",
   "metadata": {},
   "source": [
    "---\n",
    "*This notebook shows the complete workflow for English RST parsing: from EDU extraction to visualization of dependency trees for both discourse units and whole sentences.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
